{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from Bio import SeqIO\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, Dropout, MaxPooling1D, Flatten, Dense\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set seeds for reproducibility\n",
    "def set_seed(seed_value=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Set deterministic operations in TensorFlow\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9499, 33)\n",
      "(9499,)\n",
      "(3226, 33)\n",
      "(3226,)\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "win_size = 33 # actual window size\n",
    "win_size_kernel = int(win_size/2 + 1)\n",
    "\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "# TRAIN DATASET -------------------------------------------------------------\n",
    "#for positive sequence\n",
    "def inner1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    train_x.append(integer_encoded)\n",
    "    train_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"../data/train/fasta/positive_sites.fasta\", \"fasta\"): # training data positive\n",
    "    inner1()\n",
    "#for negative sequence\n",
    "def inner2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    train_x.append(integer_encoded)\n",
    "    train_y.append(negat_0)\n",
    "for seq_record in SeqIO.parse(\"../data/train/fasta/negative_sites.fasta\", \"fasta\"): # training data negative\n",
    "    inner2()\n",
    "# Changing to array (matrix)    \n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"../data/test/fasta/test_positive_sites.fasta\", \"fasta\"): # test positive\n",
    "    innertest1()\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(negat_0)\n",
    "for seq_record in SeqIO.parse(\"../data/test/fasta/test_negative_sites.fasta\", \"fasta\"): # test negative\n",
    "    innertest2()\n",
    "\n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "\n",
    "\n",
    "# epochs = 100\n",
    "# num_classes = 2\n",
    "# batch_size = 256\n",
    "# optimize_2 = tf.keras.optimizers.Adam()\n",
    "\n",
    "# loss_2 = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "# test_size = 0.2\n",
    "seed = 3\n",
    "\n",
    "X_train = train_x\n",
    "y_train = train_y\n",
    "\n",
    "X_test = r_test_x\n",
    "y_test = r_test_y\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9499, 1024)\n",
      "(9499,)\n",
      "(3226, 1024)\n",
      "(3226,)\n"
     ]
    }
   ],
   "source": [
    "train_positive_pt5 = pd.read_csv(\"../data/train/features/train_positive_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "train_negative_pt5 = pd.read_csv(\"../data/train/features/train_negative_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "test_positive_pt5 = pd.read_csv(\"../data/test/features/test_positive_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "test_negative_pt5 = pd.read_csv(\"../data/test/features/test_negative_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "\n",
    "\n",
    "# create labels\n",
    "train_positive_labels = np.ones(train_positive_pt5.shape[0])\n",
    "train_negative_labels = np.zeros(train_negative_pt5.shape[0])\n",
    "test_positive_labels = np.ones(test_positive_pt5.shape[0])\n",
    "test_negative_labels = np.zeros(test_negative_pt5.shape[0])\n",
    "\n",
    "# stack positive and negative data together\n",
    "X_train_pt5 = np.vstack((train_positive_pt5,train_negative_pt5))\n",
    "X_test_pt5 = np.vstack((test_positive_pt5,test_negative_pt5))\n",
    "y_train_pt5 = np.concatenate((train_positive_labels, train_negative_labels), axis = 0)\n",
    "y_test_pt5 = np.concatenate((test_positive_labels, test_negative_labels), axis = 0)\n",
    "\n",
    "# # shuffle X and y together\n",
    "# X_train_pt5, y_train_pt5 = shuffle(X_train_pt5, y_train_pt5)\n",
    "# X_test_pt5, y_test_pt5 = shuffle(X_test_pt5, y_test_pt5)\n",
    "print(X_train_pt5.shape)\n",
    "print(y_train_pt5.shape)\n",
    "print(X_test_pt5.shape)\n",
    "print(y_test_pt5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 1 1 1]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the split ratio and random state for reproducibility\n",
    "split_ratio = 0.1\n",
    "random_state = 42\n",
    "\n",
    "# Perform the split on the smaller dataset (X_train_pt5, y_train_pt5)\n",
    "X_train_pt5, X_val_pt5, y_train_pt5, y_val_pt5 = train_test_split(\n",
    "    X_train_pt5, y_train_pt5, test_size=split_ratio, random_state=random_state, stratify=y_train_pt5)\n",
    "\n",
    "# Use the same indices to split the larger dataset (X_train, y_train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=split_ratio, random_state=random_state, stratify=y_train)\n",
    "\n",
    "# Now, both X_val_pt5 and X_val correspond to the same split in y_train_pt5 and y_train\n",
    "print( y_val[:10])\n",
    "print( y_val_pt5[:10])\n",
    "\n",
    "# X_test = X_test[:2000]\n",
    "# y_test = y_test[:2000]\n",
    "# X_test_pt5 = X_test_pt5[:2000]\n",
    "# y_test_pt5 = y_test_pt5[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    # learning curves of model accuracy\n",
    "    plt.plot(history.history['accuracy'], label='train_acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "def evaluate_model(model, X_val = None, X_val_pt5 = None, y_val=None):\n",
    "    y_true = y_val\n",
    "    # Predict probabilities (or logits if using `from_logits=True`).\n",
    "    if X_val_pt5 is None:\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "    elif X_val is None:\n",
    "        y_pred_probs = model.predict(X_val_pt5)\n",
    "    else:\n",
    "        y_pred_probs = model.predict([X_val, X_val_pt5])\n",
    "\n",
    "    # Convert probabilities/logits to binary predictions (threshold = 0.5).\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # If y_true is one-hot encoded, convert it to binary format\n",
    "    if len(y_true.shape) > 1 and y_true.shape[1] > 1:  # Check if y_true is one-hot encoded\n",
    "        y_true = np.argmax(y_true, axis=1)  # Convert one-hot encoded y_true to binary labels\n",
    "\n",
    "    # Ensure y_pred is also 1D\n",
    "    if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1)  # Convert y_pred to binary labels if necessary\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Compute Specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'MCC: {mcc}')\n",
    "    print(f'AUC: {auc}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Specificity: {specificity}')\n",
    "    print(f'F1: {f1}')\n",
    "\n",
    "    return accuracy, mcc, auc, precision, recall, specificity, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,880</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m21\u001b[0m)    │      \u001b[38;5;34m5,376\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │      \u001b[38;5;34m1,664\u001b[0m │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m262,400\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │     \u001b[38;5;34m36,880\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m2,320\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m68\u001b[0m │ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m5\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,609</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m341,609\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,609</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m341,609\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5046 - loss: 0.6941 - val_accuracy: 0.5621 - val_loss: 0.6900\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5522 - loss: 0.6853 - val_accuracy: 0.5989 - val_loss: 0.6800\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5638 - loss: 0.6729 - val_accuracy: 0.6168 - val_loss: 0.6642\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5901 - loss: 0.6590 - val_accuracy: 0.6684 - val_loss: 0.6509\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6423 - loss: 0.6421 - val_accuracy: 0.6758 - val_loss: 0.6370\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6599 - loss: 0.6295 - val_accuracy: 0.6916 - val_loss: 0.6199\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6852 - loss: 0.6099 - val_accuracy: 0.6926 - val_loss: 0.6027\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6931 - loss: 0.5972 - val_accuracy: 0.7063 - val_loss: 0.5881\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7064 - loss: 0.5781 - val_accuracy: 0.7126 - val_loss: 0.5758\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7166 - loss: 0.5639 - val_accuracy: 0.7179 - val_loss: 0.5662\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7201 - loss: 0.5513 - val_accuracy: 0.7221 - val_loss: 0.5578\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7300 - loss: 0.5436 - val_accuracy: 0.7263 - val_loss: 0.5511\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7367 - loss: 0.5313 - val_accuracy: 0.7200 - val_loss: 0.5468\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7429 - loss: 0.5221 - val_accuracy: 0.7242 - val_loss: 0.5434\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7542 - loss: 0.5101 - val_accuracy: 0.7284 - val_loss: 0.5391\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7634 - loss: 0.5002 - val_accuracy: 0.7316 - val_loss: 0.5363\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7624 - loss: 0.4916 - val_accuracy: 0.7316 - val_loss: 0.5353\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7701 - loss: 0.4864 - val_accuracy: 0.7316 - val_loss: 0.5339\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7748 - loss: 0.4768 - val_accuracy: 0.7368 - val_loss: 0.5327\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7771 - loss: 0.4709 - val_accuracy: 0.7337 - val_loss: 0.5309\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7851 - loss: 0.4668 - val_accuracy: 0.7316 - val_loss: 0.5317\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7900 - loss: 0.4553 - val_accuracy: 0.7347 - val_loss: 0.5310\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7982 - loss: 0.4476 - val_accuracy: 0.7316 - val_loss: 0.5331\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7989 - loss: 0.4416 - val_accuracy: 0.7337 - val_loss: 0.5334\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8051 - loss: 0.4354 - val_accuracy: 0.7326 - val_loss: 0.5328\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8097 - loss: 0.4196 - val_accuracy: 0.7263 - val_loss: 0.5363\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8151 - loss: 0.4156 - val_accuracy: 0.7326 - val_loss: 0.5349\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8251 - loss: 0.4118 - val_accuracy: 0.7274 - val_loss: 0.5388\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8216 - loss: 0.3970 - val_accuracy: 0.7326 - val_loss: 0.5405\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8296 - loss: 0.3901 - val_accuracy: 0.7316 - val_loss: 0.5417\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Accuracy: 0.7336842105263158\n",
      "MCC: 0.4680170937049201\n",
      "AUC: 0.7336842105263158\n",
      "Precision: 0.722\n",
      "Recall: 0.76\n",
      "Specificity: 0.7073684210526315\n",
      "F1: 0.7405128205128205\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.7021078735275883\n",
      "MCC: 0.27463426723899376\n",
      "AUC: 0.7425492143387988\n",
      "Precision: 0.18050541516245489\n",
      "Recall: 0.7905138339920948\n",
      "Specificity: 0.6945845946855028\n",
      "F1: 0.29390154298310067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7021078735275883,\n",
       " 0.27463426723899376,\n",
       " 0.7425492143387988,\n",
       " 0.18050541516245489,\n",
       " 0.7905138339920948,\n",
       " 0.6945845946855028,\n",
       " 0.29390154298310067)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def LMSuccSite(input_shape_conv, input_shape_ann):\n",
    "    # Conv1D branch for sequence data\n",
    "    conv_input = Input(shape=input_shape_conv)\n",
    "\n",
    "    # Embedding layer\n",
    "    x_conv = Embedding(input_dim=256, output_dim=21, input_length=input_shape_conv[0])(conv_input)\n",
    "\n",
    "    x_conv = Lambda(lambda x: tf.expand_dims(x, 3))(x_conv)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x_conv = Conv2D(32, kernel_size=(17, 3), activation='relu'\n",
    "                    , kernel_initializer='he_normal', padding = 'VALID')(x_conv)\n",
    "    x_conv = Dropout(0.2)(x_conv)\n",
    "    x_conv = MaxPooling2D(pool_size=(2,2))(x_conv)\n",
    "    x_conv = Flatten()(x_conv)\n",
    "\n",
    "    x_conv = Dense(16, activation='relu', kernel_initializer='he_normal')(x_conv)\n",
    "    x_conv = Dropout(0.2)(x_conv)\n",
    "\n",
    "    # ANN branch for prot_t5 embeddings\n",
    "    ann_input = Input(shape=(input_shape_ann,))\n",
    "\n",
    "    # Simple Dense layer for ANN features with integer output\n",
    "    x_ann = Dense(256, activation='relu')(ann_input)\n",
    "    x_ann = Dropout(0.4)(x_ann)\n",
    "    x_ann = Dense(128, activation='relu')(x_ann) \n",
    "    x_ann = Dropout(0.4)(x_ann)\n",
    "\n",
    "\n",
    "    # Concatenate Conv1D and ANN branches\n",
    "    combined = Concatenate()([x_conv, x_ann])\n",
    "\n",
    "    # Simple Dense layer for combined features\n",
    "    x = Dense(16, activation='relu')(combined)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    x = Dense(4, activation='relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[conv_input, ann_input], outputs=output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model with Conv1D input shape (33,) and ANN input shape 1024\n",
    "LMSuccSite = LMSuccSite((33,), 1024)\n",
    "LMSuccSite.summary()\n",
    "\n",
    "# Fit the simple model\n",
    "history = LMSuccSite.fit([X_train, X_train_pt5], y_train, epochs=100, batch_size=256,\n",
    "                                 verbose=1, \n",
    "                                 validation_data=([X_val, X_val_pt5], y_val),\n",
    "                                 callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "                                )\n",
    "\n",
    "plot(history)\n",
    "\n",
    "# simple_model.load_weights('models/simple_model.weights.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(LMSuccSite, X_val, X_val_pt5, y_val)\n",
    "evaluate_model(LMSuccSite, X_test, X_test_pt5, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.5024 - loss: 0.6932 - val_accuracy: 0.6179 - val_loss: 0.6887\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5735 - loss: 0.6858 - val_accuracy: 0.6063 - val_loss: 0.6693\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5993 - loss: 0.6644 - val_accuracy: 0.6474 - val_loss: 0.6315\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6365 - loss: 0.6392 - val_accuracy: 0.6747 - val_loss: 0.6116\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6720 - loss: 0.6090 - val_accuracy: 0.6811 - val_loss: 0.6076\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6787 - loss: 0.6001 - val_accuracy: 0.7011 - val_loss: 0.5862\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7078 - loss: 0.5787 - val_accuracy: 0.6968 - val_loss: 0.5802\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7100 - loss: 0.5678 - val_accuracy: 0.7137 - val_loss: 0.5621\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7278 - loss: 0.5471 - val_accuracy: 0.7189 - val_loss: 0.5550\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7348 - loss: 0.5370 - val_accuracy: 0.7221 - val_loss: 0.5485\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7349 - loss: 0.5270 - val_accuracy: 0.7295 - val_loss: 0.5474\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7443 - loss: 0.5217 - val_accuracy: 0.7284 - val_loss: 0.5438\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7485 - loss: 0.5117 - val_accuracy: 0.7347 - val_loss: 0.5388\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7517 - loss: 0.5056 - val_accuracy: 0.7263 - val_loss: 0.5410\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7612 - loss: 0.4994 - val_accuracy: 0.7337 - val_loss: 0.5357\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7567 - loss: 0.4933 - val_accuracy: 0.7379 - val_loss: 0.5338\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7620 - loss: 0.4889 - val_accuracy: 0.7421 - val_loss: 0.5311\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7641 - loss: 0.4865 - val_accuracy: 0.7316 - val_loss: 0.5320\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7658 - loss: 0.4787 - val_accuracy: 0.7400 - val_loss: 0.5296\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7685 - loss: 0.4760 - val_accuracy: 0.7389 - val_loss: 0.5317\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7689 - loss: 0.4753 - val_accuracy: 0.7389 - val_loss: 0.5309\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7682 - loss: 0.4682 - val_accuracy: 0.7326 - val_loss: 0.5370\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7685 - loss: 0.4736 - val_accuracy: 0.7358 - val_loss: 0.5300\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7741 - loss: 0.4596 - val_accuracy: 0.7263 - val_loss: 0.5306\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7721 - loss: 0.4563 - val_accuracy: 0.7305 - val_loss: 0.5350\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7813 - loss: 0.4501 - val_accuracy: 0.7379 - val_loss: 0.5274\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7780 - loss: 0.4513 - val_accuracy: 0.7337 - val_loss: 0.5295\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7819 - loss: 0.4448 - val_accuracy: 0.7400 - val_loss: 0.5311\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7851 - loss: 0.4396 - val_accuracy: 0.7421 - val_loss: 0.5271\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7902 - loss: 0.4279 - val_accuracy: 0.7347 - val_loss: 0.5298\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7927 - loss: 0.4288 - val_accuracy: 0.7400 - val_loss: 0.5301\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7867 - loss: 0.4277 - val_accuracy: 0.7347 - val_loss: 0.5309\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7889 - loss: 0.4254 - val_accuracy: 0.7400 - val_loss: 0.5286\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7942 - loss: 0.4200 - val_accuracy: 0.7400 - val_loss: 0.5287\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7982 - loss: 0.4155 - val_accuracy: 0.7389 - val_loss: 0.5322\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8007 - loss: 0.4146 - val_accuracy: 0.7368 - val_loss: 0.5314\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7971 - loss: 0.4147 - val_accuracy: 0.7326 - val_loss: 0.5265\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8004 - loss: 0.4112 - val_accuracy: 0.7432 - val_loss: 0.5359\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7972 - loss: 0.4036 - val_accuracy: 0.7379 - val_loss: 0.5289\n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7917 - loss: 0.4036 - val_accuracy: 0.7495 - val_loss: 0.5355\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8029 - loss: 0.3993 - val_accuracy: 0.7411 - val_loss: 0.5402\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7987 - loss: 0.3994 - val_accuracy: 0.7453 - val_loss: 0.5367\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8086 - loss: 0.3894 - val_accuracy: 0.7474 - val_loss: 0.5395\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8125 - loss: 0.3831 - val_accuracy: 0.7442 - val_loss: 0.5538\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8151 - loss: 0.3926 - val_accuracy: 0.7389 - val_loss: 0.5328\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8052 - loss: 0.3850 - val_accuracy: 0.7358 - val_loss: 0.5397\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8137 - loss: 0.3883 - val_accuracy: 0.7337 - val_loss: 0.5383\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def create_conv_branch(input_shape_conv):\n",
    "    conv_input = Input(shape=input_shape_conv, name='conv_input')\n",
    "\n",
    "    # Embedding layer\n",
    "    x = Embedding(input_dim=256, output_dim=21, input_length=input_shape_conv[0])(conv_input)\n",
    "\n",
    "    x = Lambda(lambda x: tf.expand_dims(x, 3))(x)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = Conv2D(32, kernel_size=(17, 3), activation='relu',\n",
    "               kernel_initializer='he_normal', padding='VALID')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(16, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Output of convolutional branch\n",
    "    conv_output = Dense(16, activation='relu', name='conv_output')(x)\n",
    "\n",
    "    conv_output = Dense(1, activation='sigmoid')(conv_output)\n",
    "\n",
    "    model = Model(inputs=conv_input, outputs=conv_output, name='conv_branch')\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "# Instantiate the convolutional branch\n",
    "conv_branch = create_conv_branch((33,))\n",
    "\n",
    "# Train the convolutional branch\n",
    "conv_history = conv_branch.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Optionally, save the trained weights\n",
    "conv_branch.save_weights('conv_branch.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5775 - loss: 0.6634 - val_accuracy: 0.7116 - val_loss: 0.5806\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7156 - loss: 0.5594 - val_accuracy: 0.7221 - val_loss: 0.5490\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7482 - loss: 0.5085 - val_accuracy: 0.7232 - val_loss: 0.5468\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.4735 - val_accuracy: 0.7221 - val_loss: 0.5483\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7967 - loss: 0.4368 - val_accuracy: 0.7232 - val_loss: 0.5662\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.3837 - val_accuracy: 0.7105 - val_loss: 0.6021\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.3354 - val_accuracy: 0.7168 - val_loss: 0.6415\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.2838 - val_accuracy: 0.7316 - val_loss: 0.6891\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2346 - val_accuracy: 0.7232 - val_loss: 0.7299\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9247 - loss: 0.2011 - val_accuracy: 0.7189 - val_loss: 0.7978\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.1721 - val_accuracy: 0.7042 - val_loss: 0.8605\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.1492 - val_accuracy: 0.7200 - val_loss: 0.9170\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9483 - loss: 0.1347 - val_accuracy: 0.7295 - val_loss: 0.9108\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def create_ann_branch(input_shape_ann):\n",
    "    ann_input = Input(shape=(input_shape_ann,), name='ann_input')\n",
    "\n",
    "    x = Dense(256, activation='relu')(ann_input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Output of ANN branch\n",
    "    ann_output = Dense(1, activation='sigmoid', name='ann_output')(x)\n",
    "\n",
    "    model = Model(inputs=ann_input, outputs=ann_output, name='ann_branch')\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the ANN branch\n",
    "ann_branch = create_ann_branch(1024)\n",
    "\n",
    "# Train the ANN branch\n",
    "ann_history = ann_branch.fit(\n",
    "    X_train_pt5, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_pt5, y_val),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Optionally, save the trained weights\n",
    "ann_branch.save_weights('ann_branch.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"combined_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"combined_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │ conv_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ann_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │ lambda_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ ann_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_10… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,928</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ conv_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m21\u001b[0m)    │      \u001b[38;5;34m5,376\u001b[0m │ conv_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_10 (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embedding_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ann_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │      \u001b[38;5;34m1,664\u001b[0m │ lambda_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m262,400\u001b[0m │ ann_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_10… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2432\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │     \u001b[38;5;34m38,928\u001b[0m │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m68\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m5\u001b[0m │ dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">341,337</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m341,337\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,001</span> (152.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,001\u001b[0m (152.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">302,336</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m302,336\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6439 - loss: 0.6247 - val_accuracy: 0.7221 - val_loss: 0.5260\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7961 - loss: 0.4460 - val_accuracy: 0.7474 - val_loss: 0.5068\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8135 - loss: 0.4062 - val_accuracy: 0.7568 - val_loss: 0.5075\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8259 - loss: 0.3967 - val_accuracy: 0.7632 - val_loss: 0.5020\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8263 - loss: 0.3902 - val_accuracy: 0.7642 - val_loss: 0.4935\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8317 - loss: 0.3747 - val_accuracy: 0.7674 - val_loss: 0.4894\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8376 - loss: 0.3659 - val_accuracy: 0.7726 - val_loss: 0.4856\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8423 - loss: 0.3554 - val_accuracy: 0.7768 - val_loss: 0.4845\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8422 - loss: 0.3558 - val_accuracy: 0.7737 - val_loss: 0.4841\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8476 - loss: 0.3485 - val_accuracy: 0.7695 - val_loss: 0.4874\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8426 - loss: 0.3532 - val_accuracy: 0.7705 - val_loss: 0.4847\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8505 - loss: 0.3425 - val_accuracy: 0.7768 - val_loss: 0.4832\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8486 - loss: 0.3314 - val_accuracy: 0.7737 - val_loss: 0.4849\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8554 - loss: 0.3346 - val_accuracy: 0.7747 - val_loss: 0.4871\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8509 - loss: 0.3365 - val_accuracy: 0.7747 - val_loss: 0.4901\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8580 - loss: 0.3334 - val_accuracy: 0.7716 - val_loss: 0.4878\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8612 - loss: 0.3230 - val_accuracy: 0.7716 - val_loss: 0.4873\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8571 - loss: 0.3225 - val_accuracy: 0.7726 - val_loss: 0.4904\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8585 - loss: 0.3302 - val_accuracy: 0.7768 - val_loss: 0.4882\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8601 - loss: 0.3182 - val_accuracy: 0.7811 - val_loss: 0.4867\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8652 - loss: 0.3168 - val_accuracy: 0.7821 - val_loss: 0.4900\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8652 - loss: 0.3153 - val_accuracy: 0.7737 - val_loss: 0.4928\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Accuracy: 0.7768421052631579\n",
      "MCC: 0.5541756644879556\n",
      "AUC: 0.7768421052631579\n",
      "Precision: 0.7656565656565657\n",
      "Recall: 0.7978947368421052\n",
      "Specificity: 0.7557894736842106\n",
      "F1: 0.7814432989690722\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.7479851208927464\n",
      "MCC: 0.3280438638935064\n",
      "AUC: 0.7800966272207444\n",
      "Precision: 0.21252566735112938\n",
      "Recall: 0.8181818181818182\n",
      "Specificity: 0.7420114362596704\n",
      "F1: 0.3374083129584352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7479851208927464,\n",
       " 0.3280438638935064,\n",
       " 0.7800966272207444,\n",
       " 0.21252566735112938,\n",
       " 0.8181818181818182,\n",
       " 0.7420114362596704,\n",
       " 0.3374083129584352)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Concatenate, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def create_combined_model(conv_branch, ann_branch):\n",
    "    # Freeze the branches if you don't want to train them initially\n",
    "    conv_branch.trainable = False\n",
    "    ann_branch.trainable = False\n",
    "\n",
    "    # Define inputs\n",
    "    conv_input = conv_branch.input\n",
    "    ann_input = ann_branch.input\n",
    "\n",
    "    # Get outputs from the branches\n",
    "    conv_output = conv_branch.get_layer(index=6).output\n",
    "    ann_output = ann_branch.get_layer(index=4).output\n",
    "\n",
    "    # Concatenate the outputs\n",
    "    combined = Concatenate()([conv_output, ann_output])\n",
    "\n",
    "    # Add combined layers\n",
    "    x = Dense(16, activation='relu')(combined)\n",
    "    x = Dense(4, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    # Define the combined model\n",
    "    combined_model = Model(inputs=[conv_input, ann_input], outputs=output, name='combined_model')\n",
    "\n",
    "    # Compile the combined model\n",
    "    combined_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                           loss=BinaryCrossentropy(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    return combined_model\n",
    "\n",
    "# If you saved the weights separately, load them\n",
    "conv_branch.load_weights('conv_branch.weights.h5')\n",
    "ann_branch.load_weights('ann_branch.weights.h5')\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = create_combined_model(conv_branch, ann_branch)\n",
    "\n",
    "# View the summary\n",
    "combined_model.summary()\n",
    "\n",
    "# Train the combined model\n",
    "combined_history = combined_model.fit(\n",
    "    [X_train, X_train_pt5], y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    validation_data=([X_val, X_val_pt5], y_val),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(combined_model, X_val, X_val_pt5, y_val)\n",
    "evaluate_model(combined_model, X_test, X_test_pt5, y_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
