{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def round_layer(x):\n",
    "    return tf.math.round(x)  # Custom layer to round values to the nearest integers\n",
    "\n",
    "def build_simple_model(input_shape_conv, input_shape_ann):\n",
    "    # Conv1D branch for sequence data\n",
    "    conv_input = Input(shape=input_shape_conv)\n",
    "\n",
    "    # Embedding layer\n",
    "    x_conv = Embedding(input_dim=64, output_dim=21, input_length=input_shape_conv[0])(conv_input)\n",
    "\n",
    "    # Simple Conv1D + MaxPooling layer\n",
    "    x_conv = Conv1D(32, kernel_size=5, activation='relu', kernel_initializer='he_normal')(x_conv)\n",
    "    x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "    x_conv = Flatten()(x_conv)\n",
    "\n",
    "    # Simple Dense layer for sequence features with integer output\n",
    "    x_conv = Dense(16, activation='relu', kernel_initializer='he_normal')(x_conv)\n",
    "    x_conv = Dropout(0.2)(x_conv)\n",
    "    x_conv = Dense(8, activation='relu', kernel_initializer='he_normal')(x_conv)  # Final integer size\n",
    "\n",
    "    # ANN branch for prot_t5 embeddings\n",
    "    ann_input = Input(shape=(input_shape_ann,))\n",
    "\n",
    "    # Simple Dense layer for ANN features with integer output\n",
    "    x_ann = Dense(32, activation='relu')(ann_input)\n",
    "    x_ann = Dropout(0.2)(x_ann)\n",
    "    x_ann = Dense(8, activation='relu')(x_ann)  # Final integer size\n",
    "\n",
    "\n",
    "    # Concatenate Conv1D and ANN branches\n",
    "    combined = Concatenate()([x_conv, x_ann])\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[conv_input, ann_input], outputs=output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model with Conv1D input shape (33,) and ANN input shape 1024\n",
    "simple_model = build_simple_model((33,), 1024)\n",
    "simple_model.summary()\n",
    "\n",
    "class_weight = {0: 1.0, 1: 2.0}\n",
    "\n",
    "# Fit the simple model\n",
    "# history = simple_model.fit([X_train, X_train_pt5], y_train, epochs=100, batch_size=64,\n",
    "#                                  verbose=1, validation_data=([X_val, X_val_pt5], y_val))\n",
    "\n",
    "# plot(history)\n",
    "\n",
    "simple_model.load_weights('models/simple_model.weights.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def inception_module(input_tensor):\n",
    "    # Branch 1: Conv1D with kernel size 1\n",
    "    branch1 = Conv1D(32, kernel_size=1, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 2: Conv1D with kernel size 3\n",
    "    branch2 = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 3: Conv1D with kernel size 5\n",
    "    branch3 = Conv1D(32, kernel_size=5, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 4: Conv1D with kernel size 7\n",
    "    branch4 = Conv1D(32, kernel_size=7, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 5: MaxPooling + Conv1D with kernel size 1\n",
    "    branch5 = MaxPooling1D(pool_size=3, strides=1, padding='same')(input_tensor)\n",
    "    branch5 = Conv1D(32, kernel_size=1, activation='relu', padding='same')(branch4)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = Concatenate()([branch1, branch2, branch3, branch4, branch5])\n",
    "    return output\n",
    "\n",
    "def build_inception_model(input_shape_conv, input_shape_ann):\n",
    "    # Conv1D branch for sequence data\n",
    "    conv_input = Input(shape=input_shape_conv)\n",
    "\n",
    "    # Embedding layer\n",
    "    x_conv = Embedding(input_dim=64, output_dim=21, input_length=input_shape_conv[0])(conv_input)\n",
    "\n",
    "    # Apply Inception module instead of Conv1D\n",
    "    x_conv = inception_module(x_conv)\n",
    "\n",
    "    # MaxPooling and Flatten layers\n",
    "    x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "    x_conv = Flatten()(x_conv)\n",
    "\n",
    "    # Dense layer for sequence features\n",
    "    x_conv = Dense(16, activation='relu')(x_conv)\n",
    "    x_conv = Dropout(0.3)(x_conv)\n",
    "\n",
    "    # ANN branch for prot_t5 embeddings\n",
    "    ann_input = Input(shape=(input_shape_ann,))\n",
    "\n",
    "    # Simple Dense layer for ANN features\n",
    "    x_ann = Dense(64, activation='relu')(ann_input)\n",
    "    x_ann = Dropout(0.3)(x_ann)\n",
    "\n",
    "    # Concatenate Conv1D (Inception) and ANN branches\n",
    "    combined = Concatenate()([x_conv, x_ann])\n",
    "\n",
    "    # Output layer\n",
    "    x = Dense(16, activation='relu')(combined)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[conv_input, ann_input], outputs=output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model with Conv1D input shape (33,) and ANN input shape 1024\n",
    "inception_model = build_inception_model((33,), 1024)\n",
    "inception_model.summary()\n",
    "\n",
    "class_weight = {0: 1.0, 1: 2.0}\n",
    "\n",
    "# Fit the Inception model\n",
    "history = inception_model.fit([X_train, X_train_pt5], y_train, epochs=100, batch_size=64, verbose=1,\n",
    "                               validation_data=([X_val, X_val_pt5], y_val)\n",
    "                            )\n",
    "\n",
    "plot(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception Model Full Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def inception_module(input_tensor):\n",
    "    # Branch 1: Conv1D with kernel size 1\n",
    "    branch1 = Conv1D(32, kernel_size=1, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 2: Conv1D with kernel size 3\n",
    "    branch2 = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 3: Conv1D with kernel size 5\n",
    "    branch3 = Conv1D(32, kernel_size=5, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 4: Conv1D with kernel size 7\n",
    "    branch4 = Conv1D(32, kernel_size=7, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 5: Conv1D with kernel size 9\n",
    "    branch5 = Conv1D(32, kernel_size=9, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 6: Conv1D with kernel size 11\n",
    "    branch6 = Conv1D(32, kernel_size=11, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 7: MaxPooling + Conv1D with kernel size 1\n",
    "    branch7 = MaxPooling1D(pool_size=3, strides=1, padding='same')(input_tensor)\n",
    "    branch7 = Conv1D(32, kernel_size=1, activation='relu', padding='same')(branch7)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = Concatenate()([branch1, branch2, branch3, branch4, branch5, branch6, branch7])\n",
    "    return output\n",
    "\n",
    "def build_inception_model(input_shape_conv, input_shape_ann):\n",
    "    # Conv1D branch for sequence data\n",
    "    conv_input = Input(shape=input_shape_conv)\n",
    "\n",
    "    # Embedding layer\n",
    "    x_conv = Embedding(input_dim=64, output_dim=21, input_length=input_shape_conv[0])(conv_input)\n",
    "\n",
    "    # Apply Inception module instead of Conv1D\n",
    "    x_conv = inception_module(x_conv)\n",
    "\n",
    "    # MaxPooling and Flatten layers\n",
    "    x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "    x_conv = Flatten()(x_conv)\n",
    "\n",
    "    # Dense layer for sequence features\n",
    "    x_conv = Dense(16, activation='relu')(x_conv)\n",
    "    x_conv = Dropout(0.3)(x_conv)\n",
    "\n",
    "    # ANN branch for prot_t5 embeddings\n",
    "    ann_input = Input(shape=(input_shape_ann,))\n",
    "\n",
    "    # Simple Dense layer for ANN features\n",
    "    x_ann = Dense(64, activation='relu')(ann_input)\n",
    "    x_ann = Dropout(0.3)(x_ann)\n",
    "\n",
    "    # Concatenate Conv1D (Inception) and ANN branches\n",
    "    combined = Concatenate()([x_conv, x_ann])\n",
    "\n",
    "    # Output layer\n",
    "    x = Dense(16, activation='relu')(combined)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[conv_input, ann_input], outputs=output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the model with Conv1D input shape (33,) and ANN input shape 1024\n",
    "inception_model = build_inception_model((33,), 1024)\n",
    "inception_model.summary()\n",
    "\n",
    "# # early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# # Fit the Inception model\n",
    "# history = inception_model.fit([X_train, X_train_pt5], y_train, epochs=1000, batch_size=64, verbose=1, callbacks=[early_stopping]\n",
    "#                               , validation_data=([X_val, X_val_pt5], y_val))\n",
    "\n",
    "\n",
    "\n",
    "plot(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "def inception_module(input_tensor):\n",
    "    # Branch 1: Conv1D with kernel size 1\n",
    "    branch1 = Conv1D(32, kernel_size=1, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 2: Conv1D with kernel size 3\n",
    "    branch2 = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 3: Conv1D with kernel size 5\n",
    "    branch3 = Conv1D(32, kernel_size=5, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 4: Conv1D with kernel size 7\n",
    "    branch4 = Conv1D(32, kernel_size=7, activation='relu', padding='same')(input_tensor)\n",
    "\n",
    "    # Branch 5: MaxPooling + Conv1D with kernel size 1\n",
    "    branch5 = MaxPooling1D(pool_size=3, strides=1, padding='same')(input_tensor)\n",
    "    branch5 = Conv1D(32, kernel_size=1, activation='relu', padding='same')(branch4)\n",
    "\n",
    "    # Concatenate all branches\n",
    "    output = Concatenate()([branch1, branch2, branch3, branch4, branch5])\n",
    "    return output\n",
    "\n",
    "def build_inception_model(input_shape_conv, input_shape_ann):\n",
    "    # Conv1D branch for sequence data\n",
    "    conv_input = Input(shape=input_shape_conv)\n",
    "\n",
    "    # Embedding layer\n",
    "    x_conv = Embedding(input_dim=64, output_dim=21, input_length=input_shape_conv[0])(conv_input)\n",
    "\n",
    "    # Apply Inception module instead of Conv1D\n",
    "    x_conv = inception_module(x_conv)\n",
    "\n",
    "    # MaxPooling and Flatten layers\n",
    "    x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "    x_conv = Flatten()(x_conv)\n",
    "\n",
    "    # Dense layer for sequence features\n",
    "    x_conv = Dense(16, activation='relu')(x_conv)\n",
    "    x_conv = Dropout(0.3)(x_conv)\n",
    "\n",
    "    # ANN branch for prot_t5 embeddings\n",
    "    ann_input = Input(shape=(input_shape_ann,))\n",
    "\n",
    "    # Simple Dense layer for ANN features\n",
    "    x_ann = Dense(64, activation='relu')(ann_input)\n",
    "    x_ann = Dropout(0.3)(x_ann)\n",
    "\n",
    "    # Concatenate Conv1D (Inception) and ANN branches\n",
    "    combined = Concatenate()([x_conv, x_ann])\n",
    "\n",
    "    # Output layer\n",
    "    x = Dense(16, activation='relu')(combined)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[conv_input, ann_input], outputs=output_layer)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "set_seed(4)\n",
    "\n",
    "# Define the model with Conv1D input shape (33,) and ANN input shape 1024\n",
    "inception_model = build_inception_model((33,), 1024)\n",
    "# inception_model.summary()\n",
    "\n",
    "# Fit the Inception model\n",
    "history = inception_model.fit([X_train_num, X_train_embeddings], y_train, epochs=100, batch_size=64, verbose=1,\n",
    "                               validation_data=([X_val_num, X_val_embeddings], y_val),\n",
    "                                 callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "                            )\n",
    "\n",
    "plot(history)\n",
    "\n",
    "evaluate_model(inception_model, X_val_num, X_val_embeddings, y_val)\n",
    "evaluate_model(inception_model, X_test_num, X_test_embeddings, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
